{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering notebook\n",
    "\n",
    "This is the final version of feature engineering notebook for solar model where we prepare our data for prediction. Prediction will be placed in a separate notebook. Going a little-bit upfront, we will be trying several regression models with our data set, including Random Forest algorithm and perhaps Neural Networks. Due to decision trees nature, the features will have to be engineered slightly differently:\n",
    "> Example: \n",
    "> * Random forests do not benefit from too large feature spaces, since they select at random sqrt(p) or p/3 features, where p is total number of features. Therefore, when working with discretization and encoding of some of the numerical variables it is beneficial not to increase the feature space by one-hot encoding and using dummy variables. Instead, we will keep them in the same feature as a categorical variable.\n",
    "> * For Neural Networks we would perform data scaling that is unneccessary for decision tree algorithms.\n",
    "\n",
    "### Important notice: variable division transformations are done on the Train set\n",
    "\n",
    "Checklist and a quick overview of feature engineering steps:\n",
    "\n",
    "* missing values\n",
    "* outliers\n",
    "* discretization\n",
    "* gaussian transformation (?)\n",
    "* new features\n",
    "* feature selection (+FMI API recieved data sneakpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
